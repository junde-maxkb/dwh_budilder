import json
import logging
import os
from utils.generate_period_code import generate_period_codes
from core.org_crawler import OrgCrawler
from core.flow_crawler import FlowCrawler
from core.boe_crawler import BoeCrawler

logger = logging.getLogger(__name__)


class TaskManager:
    """ä»»åŠ¡ç®¡ç†å™¨ - è´Ÿè´£æ£€æµ‹æ–°æ•°æ®å’Œåˆ›å»ºå¤„ç†ä»»åŠ¡"""

    def __init__(self, data_processor, system_manager, db_manager):
        self.data_processor = data_processor
        self.system_manager = system_manager
        self.db_manager = db_manager

        # æ•°æ®ç±»å‹å®šä¹‰
        self.yearly_data_types = [
            'account_structure',  # ä¼šè®¡ç§‘ç›®ç»“æ„
            'subject_dimension',  # ç§‘ç›®è¾…åŠ©æ ¸ç®—å…³ç³»
            'customer_vendor',  # å®¢å•†å­—å…¸
        ]

        self.period_data_types = [
            'voucher_list',  # å‡­è¯ç›®å½•
            'voucher_detail',  # å‡­è¯æ˜ç»†
            'voucher_dim_detail',  # å‡­è¯è¾…åŠ©æ˜ç»†
            'balance',  # ç§‘ç›®ä½™é¢
            'aux_balance'  # è¾…åŠ©ä½™é¢
        ]

        current_dir = os.path.dirname(os.path.abspath(__file__))
        print(current_dir)
        company_ids_path = os.path.join(current_dir, '..', 'company_ids.json')
        print(company_ids_path)
        with open(company_ids_path, "r", encoding="utf-8") as f:
            self.company_codes = json.load(f)
        print(f"åŠ è½½äº† {len(self.company_codes)} ä¸ªå…¬å¸ä»£ç ç”¨äºä»»åŠ¡ç®¡ç†")

    def check_and_add_new_data_tasks(self) -> bool:
        """
        æ£€æŸ¥å¹¶æ·»åŠ æ–°çš„æ•°æ®ä»»åŠ¡

        Returns:
            bool: æ˜¯å¦æ·»åŠ äº†æ–°ä»»åŠ¡
        """
        logger.info("ğŸ” å¼€å§‹æ£€æŸ¥æ–°æ•°æ®...")

        try:
            # 1. æ£€æŸ¥è´¢åŠ¡æŠ¥è¡¨æ–°ä»»åŠ¡
            has_new_financial_tasks = self._check_financial_report_tasks()

            # 2. æ£€æŸ¥ä¼ ç»Ÿè´¢åŠ¡æ•°æ®æ–°ä»»åŠ¡
            has_new_traditional_tasks = self._check_traditional_data_tasks()

            # 3. æ£€æŸ¥ç»„ç»‡æ¶æ„ã€èµ„é‡‘æµæ°´ã€æŠ¥è´¦å•æ–°ä»»åŠ¡
            has_new_crawler_tasks = self._check_crawler_tasks()

            has_new_tasks = has_new_financial_tasks or has_new_traditional_tasks or has_new_crawler_tasks

            if has_new_tasks:
                logger.info("ğŸ‰ å‘ç°æ–°æ•°æ®ï¼Œå·²æ·»åŠ ç›¸åº”ä»»åŠ¡åˆ°å¤„ç†é˜Ÿåˆ—")
            else:
                logger.info("ğŸ˜´ æš‚æ— æ–°æ•°æ®éœ€è¦å¤„ç†")

            return has_new_tasks

        except Exception as e:
            logger.error(f"æ£€æŸ¥æ–°æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def _check_financial_report_tasks(self) -> bool:
        """æ£€æŸ¥è´¢åŠ¡æŠ¥è¡¨æ–°ä»»åŠ¡"""
        try:
            quarterly_monthly_tasks = self.data_processor.get_quarterly_monthly_tasks()

            if not quarterly_monthly_tasks:
                logger.info("ğŸ“Š è´¢åŠ¡æŠ¥è¡¨æ£€æŸ¥å®Œæˆï¼Œæ— æ–°ä»»åŠ¡")
                return False

            new_financial_tasks = 0

            for i, task in enumerate(quarterly_monthly_tasks):
                task_name = task.get("taskName", "")

                # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å¤„ç†è¿‡
                formatted_task_name = f"process_financial_reports_{task_name}"

                # è·å–ç³»ç»ŸçŠ¶æ€ï¼Œæ£€æŸ¥æ˜¯å¦å·²æœ‰åŒåä»»åŠ¡
                system_status = self.system_manager.get_system_status()
                existing_tasks = system_status.get("task_details", {})

                task_exists = any(formatted_task_name in task_name for task_name in existing_tasks.keys())

                if not task_exists:
                    success = self.data_processor.add_financial_report_task_to_system(
                        system_manager=self.system_manager,
                        task_info=task,
                        priority=10 + i
                    )

                    if success:
                        new_financial_tasks += 1
                        logger.info(f"âœ… å‘ç°å¹¶æ·»åŠ æ–°çš„è´¢åŠ¡æŠ¥è¡¨ä»»åŠ¡: {task_name}")

            if new_financial_tasks > 0:
                logger.info(f"ğŸ“ˆ è´¢åŠ¡æŠ¥è¡¨æ£€æŸ¥å®Œæˆï¼Œæ–°å¢ {new_financial_tasks} ä¸ªä»»åŠ¡")
                return True
            else:
                logger.info("ğŸ“Š è´¢åŠ¡æŠ¥è¡¨æ£€æŸ¥å®Œæˆï¼Œæ— æ–°ä»»åŠ¡")
                return False

        except Exception as e:
            logger.warning(f"æ£€æŸ¥è´¢åŠ¡æŠ¥è¡¨æ–°ä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def _check_traditional_data_tasks(self) -> bool:
        """æ£€æŸ¥ä¼ ç»Ÿè´¢åŠ¡æ•°æ®æ–°ä»»åŠ¡"""
        try:
            # ç”ŸæˆåŒ…å«æœ€æ–°æœˆä»½çš„æœŸé—´ä»£ç ï¼Œä»2025å¹´å¼€å§‹
            current_period_codes = generate_period_codes(start_year=2025)
            logger.debug(f"ç”Ÿæˆå½“å‰æœŸé—´ä»£ç ï¼Œæœ€æ–°æœŸé—´: {current_period_codes[-1] if current_period_codes else 'None'}")

            new_traditional_tasks = []

            # æ£€æŸ¥å¹´åº¦æ•°æ®
            processed_years = set()
            for period_code in current_period_codes:
                year = period_code.split('-')[0]

                if year not in processed_years:
                    for data_type in self.yearly_data_types:
                        for company_code in self.company_codes:
                            if not self.db_manager.check_traditional_data_exists(data_type, company_code, year=year):
                                task_config = {
                                    'data_type': data_type,
                                    'company_code': company_code,
                                    'year': year,
                                    'period_code': f"{year}-01",
                                    'priority': len(self.yearly_data_types) - self.yearly_data_types.index(data_type)
                                }
                                new_traditional_tasks.append(task_config)
                                logger.info(f"âœ… å‘ç°æ–°çš„å¹´åº¦æ•°æ®éœ€è¦å¤„ç†: {data_type} - {company_code} - {year}")

                    processed_years.add(year)

            # æ£€æŸ¥æœŸé—´æ•°æ®
            for period_code in current_period_codes:
                year = period_code.split('-')[0]

                for data_type in self.period_data_types:
                    for company_code in self.company_codes:
                        if not self.db_manager.check_traditional_data_exists(data_type, company_code,
                                                                             period_code=period_code):
                            task_config = {
                                'data_type': data_type,
                                'company_code': company_code,
                                'year': year,
                                'period_code': period_code,
                                'priority': len(self.period_data_types) - self.period_data_types.index(data_type)
                            }
                            new_traditional_tasks.append(task_config)
                            logger.info(f"âœ… å‘ç°æ–°çš„æœŸé—´æ•°æ®éœ€è¦å¤„ç†: {data_type} - {company_code} - {period_code}")

            if new_traditional_tasks:
                success = self.data_processor.add_processing_tasks_to_system(
                    self.system_manager,
                    new_traditional_tasks
                )

                if success:
                    logger.info(f"ğŸ“ˆ ä¼ ç»Ÿæ•°æ®æ£€æŸ¥å®Œæˆï¼Œæ–°å¢ {len(new_traditional_tasks)} ä¸ªä»»åŠ¡")
                    return True
                else:
                    logger.error("âŒ æ·»åŠ æ–°çš„ä¼ ç»Ÿæ•°æ®ä»»åŠ¡å¤±è´¥")
                    return False
            else:
                logger.info("ğŸ“Š ä¼ ç»Ÿæ•°æ®æ£€æŸ¥å®Œæˆï¼Œæ— æ–°ä»»åŠ¡")
                return False

        except Exception as e:
            logger.warning(f"æ£€æŸ¥ä¼ ç»Ÿæ•°æ®æ–°ä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def _check_crawler_tasks(self) -> bool:
        """æ£€æŸ¥ç»„ç»‡æ¶æ„ã€èµ„é‡‘æµæ°´ã€æŠ¥è´¦å•æ–°ä»»åŠ¡"""
        try:
            has_new_tasks = False

            # æ£€æŸ¥ç»„ç»‡æ¶æ„ä»»åŠ¡
            if not self._check_crawler_task_exists("org_crawler"):
                if self._add_crawler_task("org_crawler", self._run_org_crawler, priority=20):
                    has_new_tasks = True
                    logger.info("âœ… å‘ç°å¹¶æ·»åŠ æ–°çš„ç»„ç»‡æ¶æ„ä»»åŠ¡")

            # æ£€æŸ¥èµ„é‡‘æµæ°´ä»»åŠ¡
            if not self._check_crawler_task_exists("flow_crawler"):
                if self._add_crawler_task("flow_crawler", self._run_flow_crawler, priority=19):
                    has_new_tasks = True
                    logger.info("âœ… å‘ç°å¹¶æ·»åŠ æ–°çš„èµ„é‡‘æµæ°´ä»»åŠ¡")

            # æ£€æŸ¥æŠ¥è´¦å•ä»»åŠ¡
            if not self._check_crawler_task_exists("boe_crawler"):
                if self._add_crawler_task("boe_crawler", self._run_boe_crawler, priority=18):
                    has_new_tasks = True
                    logger.info("âœ… å‘ç°å¹¶æ·»åŠ æ–°çš„æŠ¥è´¦å•ä»»åŠ¡")

            if has_new_tasks:
                logger.info(f"ğŸ“ˆ çˆ¬è™«ä»»åŠ¡æ£€æŸ¥å®Œæˆï¼Œæ–°å¢ä»»åŠ¡")
                return True
            else:
                logger.info("ğŸ“Š çˆ¬è™«ä»»åŠ¡æ£€æŸ¥å®Œæˆï¼Œæ— æ–°ä»»åŠ¡")
                return False

        except Exception as e:
            logger.warning(f"æ£€æŸ¥çˆ¬è™«ä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def _check_crawler_task_exists(self, task_type: str) -> bool:
        """æ£€æŸ¥çˆ¬è™«ä»»åŠ¡æ˜¯å¦å·²å­˜åœ¨"""
        try:
            system_status = self.system_manager.get_system_status()
            existing_tasks = system_status.get("task_details", {})
            task_name = f"crawler_{task_type}"
            return any(task_name in task_name_key for task_name_key in existing_tasks.keys())
        except Exception as e:
            logger.warning(f"æ£€æŸ¥çˆ¬è™«ä»»åŠ¡æ˜¯å¦å­˜åœ¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def _add_crawler_task(self, task_type: str, func, priority: int = 0) -> bool:
        """æ·»åŠ çˆ¬è™«ä»»åŠ¡åˆ°ç³»ç»Ÿ"""
        try:
            task_name = f"crawler_{task_type}"
            success = self.system_manager.add_task(
                name=task_name,
                func=func,
                args=(),
                kwargs={},
                priority=priority,
                max_retries=3
            )
            return success
        except Exception as e:
            logger.error(f"æ·»åŠ çˆ¬è™«ä»»åŠ¡ {task_type} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False

    def _run_org_crawler(self):
        """è¿è¡Œç»„ç»‡æ¶æ„çˆ¬è™«ä»»åŠ¡"""
        try:
            logger.info("å¼€å§‹æ‰§è¡Œç»„ç»‡æ¶æ„çˆ¬è™«ä»»åŠ¡...")
            crawler = OrgCrawler()
            crawler.run()
            logger.info("ç»„ç»‡æ¶æ„çˆ¬è™«ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
            return {"success": True, "message": "ç»„ç»‡æ¶æ„çˆ¬è™«ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ"}
        except Exception as e:
            logger.error(f"ç»„ç»‡æ¶æ„çˆ¬è™«ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            raise

    def _run_flow_crawler(self):
        """è¿è¡Œèµ„é‡‘æµæ°´çˆ¬è™«ä»»åŠ¡"""
        try:
            logger.info("å¼€å§‹æ‰§è¡Œèµ„é‡‘æµæ°´çˆ¬è™«ä»»åŠ¡...")
            crawler = FlowCrawler()
            stats = crawler.run()
            logger.info(f"èµ„é‡‘æµæ°´çˆ¬è™«ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œç»Ÿè®¡: {stats}")
            return {"success": True, "message": "èµ„é‡‘æµæ°´çˆ¬è™«ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ", "stats": stats}
        except Exception as e:
            logger.error(f"èµ„é‡‘æµæ°´çˆ¬è™«ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            raise

    def _run_boe_crawler(self):
        """è¿è¡ŒæŠ¥è´¦å•çˆ¬è™«ä»»åŠ¡"""
        try:
            logger.info("å¼€å§‹æ‰§è¡ŒæŠ¥è´¦å•çˆ¬è™«ä»»åŠ¡...")
            crawler = BoeCrawler()
            # å¯ä»¥æ ¹æ®éœ€è¦è®¾ç½®æ—¥æœŸèŒƒå›´ï¼Œè¿™é‡Œä½¿ç”¨é»˜è®¤å€¼ï¼ˆNoneè¡¨ç¤ºçˆ¬å–æ‰€æœ‰æ•°æ®ï¼‰
            crawler.run(start_date="", end_date="")
            logger.info("æŠ¥è´¦å•çˆ¬è™«ä»»åŠ¡æ‰§è¡Œå®Œæˆ")
            return {"success": True, "message": "æŠ¥è´¦å•çˆ¬è™«ä»»åŠ¡æ‰§è¡ŒæˆåŠŸ"}
        except Exception as e:
            logger.error(f"æŠ¥è´¦å•çˆ¬è™«ä»»åŠ¡æ‰§è¡Œå¤±è´¥: {e}")
            raise

    def _create_initial_crawler_tasks(self) -> bool:
        """åˆ›å»ºåˆå§‹çˆ¬è™«ä»»åŠ¡ï¼ˆç»„ç»‡æ¶æ„ã€èµ„é‡‘æµæ°´ã€æŠ¥è´¦å•ï¼‰"""
        logger.info("æ­¥éª¤3: åˆæ¬¡å¯åŠ¨ - æ·»åŠ çˆ¬è™«ä»»åŠ¡åˆ°é˜Ÿåˆ—ï¼ˆç»„ç»‡æ¶æ„ã€èµ„é‡‘æµæ°´ã€æŠ¥è´¦å•ï¼‰")

        try:
            tasks_added = 0

            # æ·»åŠ ç»„ç»‡æ¶æ„ä»»åŠ¡
            if not self._check_crawler_task_exists("org_crawler"):
                if self._add_crawler_task("org_crawler", self._run_org_crawler, priority=20):
                    tasks_added += 1
                    logger.info("âœ… ç»„ç»‡æ¶æ„ä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ—")
                else:
                    logger.error("âŒ æ·»åŠ ç»„ç»‡æ¶æ„ä»»åŠ¡å¤±è´¥")
            else:
                logger.info("ç»„ç»‡æ¶æ„ä»»åŠ¡å·²å­˜åœ¨ï¼Œè·³è¿‡")

            # æ·»åŠ èµ„é‡‘æµæ°´ä»»åŠ¡
            if not self._check_crawler_task_exists("flow_crawler"):
                if self._add_crawler_task("flow_crawler", self._run_flow_crawler, priority=19):
                    tasks_added += 1
                    logger.info("âœ… èµ„é‡‘æµæ°´ä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ—")
                else:
                    logger.error("âŒ æ·»åŠ èµ„é‡‘æµæ°´ä»»åŠ¡å¤±è´¥")
            else:
                logger.info("èµ„é‡‘æµæ°´ä»»åŠ¡å·²å­˜åœ¨ï¼Œè·³è¿‡")

            # æ·»åŠ æŠ¥è´¦å•ä»»åŠ¡
            if not self._check_crawler_task_exists("boe_crawler"):
                if self._add_crawler_task("boe_crawler", self._run_boe_crawler, priority=18):
                    tasks_added += 1
                    logger.info("âœ… æŠ¥è´¦å•ä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ—")
                else:
                    logger.error("âŒ æ·»åŠ æŠ¥è´¦å•ä»»åŠ¡å¤±è´¥")
            else:
                logger.info("æŠ¥è´¦å•ä»»åŠ¡å·²å­˜åœ¨ï¼Œè·³è¿‡")

            success = tasks_added > 0
            logger.info(f"çˆ¬è™«ä»»åŠ¡æ·»åŠ å®Œæˆï¼ŒæˆåŠŸæ·»åŠ  {tasks_added} ä¸ªä»»åŠ¡")
            return success

        except Exception as e:
            logger.error(f"æ·»åŠ çˆ¬è™«ä»»åŠ¡åˆ°é˜Ÿåˆ—æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            return False

    def create_initial_tasks(self) -> tuple[bool, bool, bool]:
        """
        åˆ›å»ºåˆå§‹å¯åŠ¨ä»»åŠ¡

        Returns:
            tuple: (è´¢åŠ¡æŠ¥è¡¨ä»»åŠ¡æ˜¯å¦æˆåŠŸ, ä¼ ç»Ÿæ•°æ®ä»»åŠ¡æ˜¯å¦æˆåŠŸ, çˆ¬è™«ä»»åŠ¡æ˜¯å¦æˆåŠŸ)
        """
        try:
            # åˆ›å»ºåˆå§‹è´¢åŠ¡æŠ¥è¡¨ä»»åŠ¡
            financial_success = self._create_initial_financial_tasks()

            # åˆ›å»ºåˆå§‹ä¼ ç»Ÿæ•°æ®ä»»åŠ¡
            traditional_success = self._create_initial_traditional_tasks()

            # åˆ›å»ºåˆå§‹çˆ¬è™«ä»»åŠ¡ï¼ˆç»„ç»‡æ¶æ„ã€èµ„é‡‘æµæ°´ã€æŠ¥è´¦å•ï¼‰
            crawler_success = self._create_initial_crawler_tasks()

            return financial_success, traditional_success, crawler_success

        except Exception as e:
            logger.error(f"åˆ›å»ºåˆå§‹ä»»åŠ¡æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            return False, False, False

    def _create_initial_financial_tasks(self) -> bool:
        """åˆ›å»ºåˆå§‹è´¢åŠ¡æŠ¥è¡¨ä»»åŠ¡"""
        logger.info("æ­¥éª¤1: åˆæ¬¡å¯åŠ¨ - æ·»åŠ è´¢åŠ¡æŠ¥è¡¨ä»»åŠ¡åˆ°é˜Ÿåˆ—")

        try:
            quarterly_monthly_tasks = self.data_processor.get_quarterly_monthly_tasks()

            if not quarterly_monthly_tasks:
                logger.warning("æœªæ‰¾åˆ°å­£æŠ¥æœˆæŠ¥ä»»åŠ¡")
                return False

            financial_tasks_added = 0

            for i, task in enumerate(quarterly_monthly_tasks):
                task_name = task.get("taskName", "")
                logger.info(f"æ·»åŠ è´¢åŠ¡æŠ¥è¡¨ä»»åŠ¡ - ä»»åŠ¡åç§°: {task_name}")

                success = self.data_processor.add_financial_report_task_to_system(
                    system_manager=self.system_manager,
                    task_info=task,
                    priority=10 + i
                )

                if success:
                    financial_tasks_added += 1
                    logger.info(f"âœ… è´¢åŠ¡æŠ¥è¡¨ä»»åŠ¡å·²æ·»åŠ åˆ°é˜Ÿåˆ— - ä»»åŠ¡åç§°: {task_name}")
                else:
                    logger.error(f"âŒ æ·»åŠ è´¢åŠ¡æŠ¥è¡¨ä»»åŠ¡å¤±è´¥ - ä»»åŠ¡åç§°: {task_name}")

            success = financial_tasks_added > 0
            logger.info(f"è´¢åŠ¡æŠ¥è¡¨ä»»åŠ¡æ·»åŠ å®Œæˆï¼ŒæˆåŠŸæ·»åŠ  {financial_tasks_added} ä¸ªä»»åŠ¡")

            return success

        except Exception as e:
            logger.error(f"æ·»åŠ è´¢åŠ¡æŠ¥è¡¨ä»»åŠ¡åˆ°é˜Ÿåˆ—æ—¶å‘ç”Ÿé”™è¯¯: {e}", exc_info=True)
            return False

    def _create_initial_traditional_tasks(self) -> bool:
        """åˆ›å»ºåˆå§‹ä¼ ç»Ÿæ•°æ®ä»»åŠ¡"""
        logger.info("æ­¥éª¤2: åˆæ¬¡å¯åŠ¨ - æ·»åŠ ä¼ ç»Ÿè´¢åŠ¡æ•°æ®ä»»åŠ¡åˆ°é˜Ÿåˆ—")

        period_codes = generate_period_codes(start_year=2025)
        logger.info(f"ç”Ÿæˆäº† {len(period_codes)} ä¸ªæœŸé—´ä»£ç : {period_codes[:5]}...{period_codes[-5:]}")

        # è¿‡æ»¤å·²å­˜åœ¨çš„æ•°æ®
        logger.info("å¼€å§‹æ£€æŸ¥å·²å­˜åœ¨çš„æ•°æ®ï¼Œè¿‡æ»¤é‡å¤ä»»åŠ¡...")

        all_tasks_config = []

        # 1. å¤„ç†æŒ‰å¹´ä»½çš„æ•°æ®ï¼Œå…ˆè¿‡æ»¤å·²å­˜åœ¨çš„
        processed_years = set()
        skipped_yearly_tasks = 0
        for period_code in period_codes:
            year = period_code.split('-')[0]

            if year not in processed_years:
                for data_type in self.yearly_data_types:
                    for company_code in self.company_codes:
                        if self.db_manager.check_traditional_data_exists(data_type, company_code, year=year):
                            skipped_yearly_tasks += 1
                            logger.debug(
                                f"è·³è¿‡å·²å­˜åœ¨çš„å¹´åº¦æ•°æ® - ç±»å‹: {data_type}, å…¬å¸: {company_code}, å¹´ä»½: {year}")
                            continue

                        task_config = {
                            'data_type': data_type,
                            'company_code': company_code,
                            'year': year,
                            'period_code': f"{year}-01",
                            'priority': len(self.yearly_data_types) - self.yearly_data_types.index(data_type)
                        }
                        all_tasks_config.append(task_config)

                processed_years.add(year)

        logger.info(f"å¹´åº¦æ•°æ®æ£€æŸ¥å®Œæˆï¼Œè·³è¿‡ {skipped_yearly_tasks} ä¸ªå·²å­˜åœ¨çš„ä»»åŠ¡")

        # 2. å¤„ç†æŒ‰æœŸé—´çš„æ•°æ®ï¼Œå…ˆè¿‡æ»¤å·²å­˜åœ¨çš„
        skipped_period_tasks = 0
        for period_code in period_codes:
            year = period_code.split('-')[0]

            for data_type in self.period_data_types:
                for company_code in self.company_codes:
                    if self.db_manager.check_traditional_data_exists(data_type, company_code, period_code=period_code):
                        skipped_period_tasks += 1
                        logger.debug(
                            f"è·³è¿‡å·²å­˜åœ¨çš„æœŸé—´æ•°æ® - ç±»å‹: {data_type}, å…¬å¸: {company_code}, æœŸé—´: {period_code}")
                        continue

                    task_config = {
                        'data_type': data_type,
                        'company_code': company_code,
                        'year': year,
                        'period_code': period_code,
                        'priority': len(self.period_data_types) - self.period_data_types.index(data_type)
                    }
                    all_tasks_config.append(task_config)

        logger.info(f"æœŸé—´æ•°æ®æ£€æŸ¥å®Œæˆï¼Œè·³è¿‡ {skipped_period_tasks} ä¸ªå·²å­˜åœ¨çš„ä»»åŠ¡")

        total_skipped = skipped_yearly_tasks + skipped_period_tasks
        logger.info(f"åˆæ¬¡å¯åŠ¨æ•°æ®å»é‡å®Œæˆï¼š")
        logger.info(f"  - è·³è¿‡çš„é‡å¤ä»»åŠ¡æ•°: {total_skipped}")
        logger.info(f"  - å®é™…éœ€è¦æ‰§è¡Œçš„ä»»åŠ¡æ•°: {len(all_tasks_config)}")

        if not all_tasks_config:
            logger.info("æ‰€æœ‰ä¼ ç»Ÿæ•°æ®ä»»åŠ¡éƒ½å·²å­˜åœ¨ï¼Œæ— éœ€é‡å¤å¤„ç†")
            return True

        success = self.data_processor.add_processing_tasks_to_system(
            self.system_manager,
            all_tasks_config
        )

        if success:
            logger.info(f"æˆåŠŸæ·»åŠ  {len(all_tasks_config)} ä¸ªæ–°çš„ä¼ ç»Ÿæ•°æ®å¤„ç†ä»»åŠ¡åˆ°é˜Ÿåˆ—")
            return True
        else:
            logger.error("æ·»åŠ ä¼ ç»Ÿæ•°æ®ä»»åŠ¡åˆ°é˜Ÿåˆ—æ—¶å‘ç”Ÿé”™è¯¯")
            return False
